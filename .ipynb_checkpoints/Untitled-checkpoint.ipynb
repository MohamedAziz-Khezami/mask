{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61401445-db73-4c4a-81b7-3d2759b8c0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, File, UploadFile, HTTPException\n",
    "from fastapi.responses import JSONResponse, StreamingResponse\n",
    "import os\n",
    "import base64\n",
    "import numpy as np\n",
    "import cv2\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib import pyplot as plt\n",
    "from segment_anything import SamPredictor\n",
    "from segment_anything import sam_model_registry\n",
    "from groundingdino.util.inference import Model\n",
    "import supervision as sv\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a309ffc1-7779-457e-b71d-6938a520bc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Chargement des poids et modèles\n",
    "GROUNDING_DINO_CONFIG_PATH = os.path.join(\n",
    "    \"GroundingDINO\", \"groundingdino\", \"config\", \"GroundingDINO_SwinT_OGC.py\"\n",
    ")\n",
    "GROUNDING_DINO_CHECKPOINT_PATH = os.path.join(\"weights\", \"groundingdino_swint_ogc.pth\")\n",
    "SAM_CHECKPOINT_PATH = os.path.join(\"weights\", \"sam_vit_h_4b8939.pth\")\n",
    "\n",
    "if not os.path.exists(GROUNDING_DINO_CHECKPOINT_PATH):\n",
    "    os.system(f\"wget -q -P {os.path.join('weights')} https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth\")\n",
    "\n",
    "if not os.path.exists(SAM_CHECKPOINT_PATH):\n",
    "    os.system(f\"wget -q -P {os.path.join('weights')} https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\")\n",
    "\n",
    "grounding_dino_model = Model(\n",
    "    model_config_path=GROUNDING_DINO_CONFIG_PATH,\n",
    "    model_checkpoint_path=GROUNDING_DINO_CHECKPOINT_PATH,\n",
    "    device=DEVICE\n",
    ")\n",
    "SAM_ENCODER_VERSION = \"vit_h\"\n",
    "sam = sam_model_registry[SAM_ENCODER_VERSION](checkpoint=SAM_CHECKPOINT_PATH).to(DEVICE)\n",
    "sam_predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60dba446-ee0e-44c5-887e-ad52f207ecdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ['window','door']\n",
    "BOX_THRESHOLD = 0.35\n",
    "TEXT_THRESHOLD = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ba2d8c5-7fd5-414c-8e6d-9511b5286b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- Fonctions principales -----------------------------\n",
    "def enhance_class_name(class_names):\n",
    "    return [f\"all {class_name}s\" for class_name in class_names]\n",
    "\n",
    "def segment_with_sam(sam_predictor, image, xyxy):\n",
    "    sam_predictor.set_image(image)\n",
    "    result_masks = []\n",
    "    for box in xyxy:\n",
    "        masks, scores, _ = sam_predictor.predict(box=box, multimask_output=True)\n",
    "        index = np.argmax(scores)\n",
    "        result_masks.append(masks[index])\n",
    "    return np.array(result_masks)\n",
    "\n",
    "def creating_mask_with_dino(image):\n",
    "    detections = grounding_dino_model.predict_with_classes(\n",
    "        image=image,\n",
    "        classes=enhance_class_name(CLASSES),\n",
    "        box_threshold=BOX_THRESHOLD,\n",
    "        text_threshold=TEXT_THRESHOLD\n",
    "    )\n",
    "    detections.xyxy = detections.xyxy.astype(int)\n",
    "    detections.mask = segment_with_sam(\n",
    "        sam_predictor=sam_predictor,\n",
    "        image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB),\n",
    "        xyxy=detections.xyxy\n",
    "    )\n",
    "\n",
    "    mask_annotator = sv.MaskAnnotator()\n",
    "    annotated_image = mask_annotator.annotate(scene=image.copy(), detections=detections)\n",
    "\n",
    "    if len(detections.mask) == 0:\n",
    "        white_image = np.ones_like(image) * 255  # Image blanche\n",
    "        white_buffer = BytesIO()\n",
    "        Image.fromarray(cv2.cvtColor(white_image, cv2.COLOR_BGR2RGB)).save(white_buffer, format=\"PNG\")\n",
    "        return white_buffer.getvalue(), white_buffer.getvalue()\n",
    "\n",
    "\n",
    "    custom_cmap = LinearSegmentedColormap.from_list(\"white_black\", [\"white\", \"black\"], N=256)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=int(np.ceil(np.sqrt(len(detections.mask)))),\n",
    "        ncols=int(np.ceil(np.sqrt(len(detections.mask)))),\n",
    "        figsize=(16, 16)\n",
    "    )\n",
    "    axes = np.array(axes).flatten()\n",
    "    for idx, ax in enumerate(axes):\n",
    "        if idx < len(detections.mask):\n",
    "            ax.imshow(detections.mask[idx], cmap=custom_cmap)\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "\n",
    "    fig.patch.set_facecolor(\"white\")\n",
    "    buf = BytesIO()\n",
    "    plt.savefig(buf, format='png', bbox_inches='tight', pad_inches=0, facecolor=\"white\")\n",
    "    buf.seek(0)\n",
    "\n",
    "    annotated_image_pil = Image.fromarray(cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))\n",
    "    annotated_buffer = BytesIO()\n",
    "    annotated_image_pil.save(annotated_buffer, format=\"PNG\")\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "    return buf.getvalue(), annotated_buffer.getvalue()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ccc16f-078f-4a25-8348-ac77c072d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(file.file)\n",
    "image_np = np.array(image)\n",
    "mask_png, _ = creating_mask_with_dino(image_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3fde12-16d3-4635-b40e-a010e7e2d836",
   "metadata": {},
   "source": [
    "- annotation problem ( the color of the original image changes )\n",
    "- mask sometimes coordinates are not good\n",
    "- https://7fi81jlb8kssrm-5000.proxy.runpod.net/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cc1637-ccb0-4b79-9dce-ade18095bbb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5b6b69-8c3b-4beb-9530-57b871254065",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ----------------------------- Routes FastAPI -----------------------------\n",
    "@app.post(\"/mask/png\")\n",
    "async def get_mask_as_png(file: UploadFile = File(...)):\n",
    "    try:\n",
    "        image = Image.open(file.file)\n",
    "        image_np = np.array(image)\n",
    "        mask_png, _ = creating_mask_with_dino(image_np)\n",
    "        return StreamingResponse(BytesIO(mask_png), media_type=\"image/png\")\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Erreur lors de la génération des masques : {str(e)}\")\n",
    "\n",
    "@app.post(\"/mask/json\")\n",
    "async def get_mask_as_json(file: UploadFile = File(...)):\n",
    "    try:\n",
    "        image = Image.open(file.file)\n",
    "        image_np = np.array(image)\n",
    "        mask_png, annotated_png = creating_mask_with_dino(image_np)\n",
    "\n",
    "        mask_base64 = base64.b64encode(mask_png).decode('utf-8')\n",
    "        annotated_base64 = base64.b64encode(annotated_png).decode('utf-8')\n",
    "\n",
    "        return JSONResponse(content={\n",
    "            \"mask\": mask_base64,\n",
    "            \"result\": annotated_base64\n",
    "        })\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Erreur lors de la génération des masques : {str(e)}\")\n",
    "\n",
    "\n",
    "@app.post(\"/mask/json\")\n",
    "async def get_mask_as_json(file: UploadFile = File(...)):\n",
    "    try:\n",
    "        image = Image.open(file.file)\n",
    "        image_np = np.array(image)\n",
    "        mask_png, annotated_png = creating_mask_with_dino(image_np)\n",
    "\n",
    "        mask_base64 = base64.b64encode(mask_png).decode('utf-8')\n",
    "        annotated_base64 = base64.b64encode(annotated_png).decode('utf-8')\n",
    "\n",
    "        return JSONResponse(content={\n",
    "            \"mask\": mask_base64,\n",
    "            \"result\": annotated_base64\n",
    "        })\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Erreur lors de la génération des masques : {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=5000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
